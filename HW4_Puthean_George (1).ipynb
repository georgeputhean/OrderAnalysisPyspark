{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_Puthean_George.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Spark and Spark SQL"
      ],
      "metadata": {
        "id": "bE-9Cxg7dA28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## George Puthean"
      ],
      "metadata": {
        "id": "H1bl0eoPTVmx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kXYsSzw6aeBE"
      },
      "outputs": [],
      "source": [
        "# install Java Virtual Machine (JVM) from OpenJDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download and decompress Apache Spark with Hadoop from https://spark.apache.org/downloads.html\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "aiPdf3_Saz2W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set environment path\n",
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ['SPARK_HOME'] = '/content/spark-3.2.1-bin-hadoop3.2'"
      ],
      "metadata": {
        "id": "9Hrlj1IXcTBQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install and import findspark to locate Spark on the system\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "id": "pr3AiejHcoAT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9a0999f-e09e-4d63-b4dc-ff4cd11adfef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.2.1-bin-hadoop3.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spark resilient distributed dataset (RDD)\n",
        "import pyspark\n",
        "sc = pyspark.SparkContext(appName='hw4')\n",
        "data = list(range(7)) #store the data\n",
        "rdd = sc.parallelize(data)\n",
        "rdd.getNumPartitions(), rdd.collect()"
      ],
      "metadata": {
        "id": "JqtO5D99CN3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f35e792-bdaf-4623-fc1a-d84ae64dba60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, [0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import SparkSession from pyspark.sql and create a SparkSession, which is the entry point to Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local').appName('Colab').config('spark.ui.port', '4050').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "-cfJx55Bc0Bq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "88ac2f2b-f970-4919-ee91-6ecde270d293"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f3789c75a50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8d82d2d1d9ae:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>hw4</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# authorize Colab to access Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AagtxRNgC_1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915badcf-b267-478f-a4f6-aad4e152a080"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data into PySpark\n",
        "df_product = spark.read.json('/content/drive/My Drive/hw4_product.json')\n",
        "df_order = spark.read.json('/content/drive/My Drive/hw4_order.json')\n",
        "df_orderline = spark.read.json('/content/drive/My Drive/hw4_orderline.json')\n",
        "df_customer = spark.read.json('/content/drive/My Drive/hw4_customer.json')"
      ],
      "metadata": {
        "id": "fFMBrjYDeBaw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show column details\n",
        "df_customer.printSchema()"
      ],
      "metadata": {
        "id": "wRCQAeYoeHAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3da97c-9c67-4ab6-9938-c8835817b4d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customerAddress: string (nullable = true)\n",
            " |-- customerCity: string (nullable = true)\n",
            " |-- customerID: long (nullable = true)\n",
            " |-- customerName: string (nullable = true)\n",
            " |-- customerPostalCode: string (nullable = true)\n",
            " |-- customerState: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display rows from top\n",
        "df_product.show(7)"
      ],
      "metadata": {
        "id": "bGLwobgVeKS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8586c653-ee80-49e9-ccc8-0e0daf69b2c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+---------+-------------+--------------------+\n",
            "|  productDescription|productFinish|productID|productLineID|productStandardPrice|\n",
            "+--------------------+-------------+---------+-------------+--------------------+\n",
            "|    Cherry End Table|       Cherry|        1|            1|               175.0|\n",
            "| Birch Coffee Tables|        Birch|        2|            1|               200.0|\n",
            "|   Oak Computer Desk|          Oak|        3|            1|               750.0|\n",
            "|Entertainment Center|       Cherry|        4|            1|              1650.0|\n",
            "|       Writer's Desk|          Oak|        5|            2|               325.0|\n",
            "|    8-Drawer Dresser|        Birch|        6|            1|               750.0|\n",
            "|         48 Bookcase|       Walnut|        7|            3|               150.0|\n",
            "+--------------------+-------------+---------+-------------+--------------------+\n",
            "only showing top 7 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1\n",
        "\n",
        "What are the description, finish and standard price of product, which standard price is less than $275 in the ascending order?\n"
      ],
      "metadata": {
        "id": "nzWBurb7NfAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter rows then select columns\n",
        "df_product.filter('productStandardPrice < 275').select('productDescription', 'productFinish', 'productStandardPrice').sort(df_product.productStandardPrice).show()"
      ],
      "metadata": {
        "id": "yLWkQ8bwedX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b3559b-9be4-4bdd-f90d-8051f90daf3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------+--------------------+\n",
            "| productDescription|productFinish|productStandardPrice|\n",
            "+-------------------+-------------+--------------------+\n",
            "|        48 Bookcase|       Walnut|               150.0|\n",
            "|         Nightstand|       Cherry|               150.0|\n",
            "|   Cherry End Table|       Cherry|               175.0|\n",
            "|        48 Bookcase|          Oak|               175.0|\n",
            "|Birch Coffee Tables|        Birch|               200.0|\n",
            "|        96 Bookcase|          Oak|               200.0|\n",
            "|        96 Bookcase|       Walnut|               225.0|\n",
            "|     Pine End Table|         Pine|               256.0|\n",
            "+-------------------+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2\n",
        "\n",
        "What are the description, finish and standard price of all desks and all tables that cost more than $300 in the descending order?\n"
      ],
      "metadata": {
        "id": "OUz7Q4HgZXSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select columns then filter rows\n",
        "df_product.select('productDescription', 'productFinish', 'productStandardPrice').filter( 'productDescription like \"%Desk%\" AND productStandardPrice > 300').sort(df_product.productStandardPrice.desc()).show()"
      ],
      "metadata": {
        "id": "N7QRkOd4ehtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4861e4b4-3d50-44c4-ce98-97a0b6ea34cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-------------+--------------------+\n",
            "|productDescription|productFinish|productStandardPrice|\n",
            "+------------------+-------------+--------------------+\n",
            "| Oak Computer Desk|          Oak|               750.0|\n",
            "|     Writer's Desk|          Oak|               325.0|\n",
            "+------------------+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q3**\n",
        "What are the description and finish of product that has been ordered in the ascending order of finish then description?"
      ],
      "metadata": {
        "id": "f70r0p3OaN7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_product.select('productDescription', 'productFinish').orderBy(df_product.productFinish,df_product.productDescription).show()"
      ],
      "metadata": {
        "id": "JFwjjf4haQMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80836b40-8a3f-461b-ac61-46dad3242e67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+\n",
            "|  productDescription|productFinish|\n",
            "+--------------------+-------------+\n",
            "|    8-Drawer Dresser|        Birch|\n",
            "| Birch Coffee Tables|        Birch|\n",
            "|       Writer's Desk|        Birch|\n",
            "|    Cherry End Table|       Cherry|\n",
            "|Entertainment Center|       Cherry|\n",
            "|          Nightstand|       Cherry|\n",
            "|High Back Leather...|      Leather|\n",
            "|    4-Drawer Dresser|          Oak|\n",
            "|         48 Bookcase|          Oak|\n",
            "|6' Grandfather Clock|          Oak|\n",
            "|7' Grandfather Clock|          Oak|\n",
            "|    8-Drawer Dresser|          Oak|\n",
            "|         96 Bookcase|          Oak|\n",
            "|   Oak Computer Desk|          Oak|\n",
            "|       Writer's Desk|          Oak|\n",
            "|      Pine End Table|         Pine|\n",
            "|         48 Bookcase|       Walnut|\n",
            "|         96 Bookcase|       Walnut|\n",
            "|              Amoire|       Walnut|\n",
            "+--------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4\n",
        "What are the name (no truncation), city and state of customer in Florida, Texas, California or Hawaii in the ascending order of name?\n"
      ],
      "metadata": {
        "id": "nKU-TRypdzDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_customer.select('customerName', 'customerCity', 'customerState').filter('customerState in (\"FL\",\"TX\",\"CA\",\"HI\")').sort(df_customer.customerName).show(truncate=0)"
      ],
      "metadata": {
        "id": "VFjYQHvsbNiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a54156-ab37-4be4-a8ec-f63bb8995ac9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+------------+-------------+\n",
            "|customerName            |customerCity|customerState|\n",
            "+------------------------+------------+-------------+\n",
            "|California Classics     |Santa Clara |CA           |\n",
            "|Contemporary Casuals    |Gainesville |FL           |\n",
            "|Impressions             |Sacramento  |CA           |\n",
            "|Kaneohe Homes           |Kaneohe     |HI           |\n",
            "|M and H Casual Furniture|Clearwater  |FL           |\n",
            "|Seminole Interiors      |Seminole    |FL           |\n",
            "|Value Furniture         |Plano       |TX           |\n",
            "+------------------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5\n",
        "\n",
        "How many customers in each of the state Florida, Texas, California or Hawaii?"
      ],
      "metadata": {
        "id": "yTTEeoQ-eQr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_customer.filter('customerState in (\"FL\",\"TX\",\"CA\",\"HI\")').groupby('customerState').count().show()"
      ],
      "metadata": {
        "id": "-yO74EsYbNfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab9bf36-6cef-4713-db03-afc3e01d08bd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|customerState|count|\n",
            "+-------------+-----+\n",
            "|           CA|    2|\n",
            "|           TX|    1|\n",
            "|           FL|    3|\n",
            "|           HI|    1|\n",
            "+-------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6\n",
        "What is the average standard price for all products in inventory?"
      ],
      "metadata": {
        "id": "h7_dbmKrgEbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "df_product.agg(mean('productStandardPrice')).show()"
      ],
      "metadata": {
        "id": "5SoFxlr9bNc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ec00ea-b0cb-4619-b406-d6a7f240ae54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|avg(productStandardPrice)|\n",
            "+-------------------------+\n",
            "|        534.6315789473684|\n",
            "+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7\n",
        "\n",
        "What are the product description, product finish, and the price higher than the average standard price for all products in inventory, in the descending order of price difference?\n"
      ],
      "metadata": {
        "id": "F6HHxL5Qnlg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the most expensive product\n",
        "from pyspark.sql.functions import mean\n",
        "df_slt = df_product.select('productDescription', 'productFinish', 'productStandardPrice')\n",
        "meanValue = df_slt.agg(mean('productStandardPrice')).collect()[0][0]\n",
        "print(f'average price = {meanValue}')\n",
        "df_slt.filter(df_product.productStandardPrice > meanValue).show()"
      ],
      "metadata": {
        "id": "ARRmb55PbNZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8af8c6e-90af-4a33-8b2d-61347ec8c092"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average price = 534.6315789473684\n",
            "+--------------------+-------------+--------------------+\n",
            "|  productDescription|productFinish|productStandardPrice|\n",
            "+--------------------+-------------+--------------------+\n",
            "|   Oak Computer Desk|          Oak|               750.0|\n",
            "|Entertainment Center|       Cherry|              1650.0|\n",
            "|    8-Drawer Dresser|        Birch|               750.0|\n",
            "|    8-Drawer Dresser|          Oak|               800.0|\n",
            "|6' Grandfather Clock|          Oak|               890.0|\n",
            "|7' Grandfather Clock|          Oak|              1100.0|\n",
            "|              Amoire|       Walnut|              1200.0|\n",
            "+--------------------+-------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8\n",
        "What are the order id, order date, the customer name (no truncation), and the overall total price for each order, in the ascending order of order id?"
      ],
      "metadata": {
        "id": "iCcztSJ0ofQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_order_customer=df_order.join(df_customer, df_order.customerID == df_customer.customerID, 'left').select('orderID','orderDate','customerName')\n",
        "df_or_cust_line=df_order_customer.join(df_orderline,df_order_customer.orderID == df_orderline.orderID, 'left').select(df_order_customer.orderID,'orderDate','customerName','orderedQuantity','productID')\n",
        "df_set_table=df_or_cust_line.join(df_product,df_or_cust_line.productID == df_product.productID,'left').select('orderID','orderDate','customerName',(df_or_cust_line.orderedQuantity*df_product.productStandardPrice).alias('totalAmount'))\n",
        "from pyspark.sql.functions import sum\n",
        "df_total_set=df_set_table.groupBy('orderID').agg(sum('totalAmount').alias('overalltotal'))\n",
        "df_total_set=df_set_table.groupBy('orderID','orderDate','customerName').agg(sum('totalAmount').alias('overalltotal'))\n",
        "df_total_set.sort('orderID').show(truncate=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034117dc-01fc-4c48-c20e-bc38a94b0f2a",
        "id": "KOtXUYOd22O9"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------------+------------+\n",
            "|orderID|orderDate |customerName            |overalltotal|\n",
            "+-------+----------+------------------------+------------+\n",
            "|1001   |2010-10-21|Contemporary Casuals    |2400.0      |\n",
            "|1002   |2010-10-21|California Classics     |3750.0      |\n",
            "|1003   |2010-10-22|Mountain Scenes         |2250.0      |\n",
            "|1004   |2010-10-22|Impressions             |1850.0      |\n",
            "|1005   |2010-10-24|Home Furnishings        |4950.0      |\n",
            "|1006   |2010-10-24|Value Furniture         |2600.0      |\n",
            "|1007   |2010-10-27|American Euro Lifestyles|925.0       |\n",
            "|1008   |2010-10-30|Battle Creek Furniture  |2775.0      |\n",
            "|1009   |2010-11-05|Eastern Furniture       |3750.0      |\n",
            "|1010   |2010-11-05|Contemporary Casuals    |1750.0      |\n",
            "+-------+----------+------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q9\n",
        "What are the id, name (no truncation), full address, and number of orders (0 if no order) for all customers, in the ascending order of customer id?\n",
        "\n"
      ],
      "metadata": {
        "id": "JuG8WkaqVjBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_cust_order=df_customer.join(df_order,df_customer.customerID==df_order.customerID,'left').select(df_customer.customerID,'customerName','customerAddress','orderID')\n",
        "\n",
        "from pyspark.sql.functions import countDistinct\n",
        "df_cust_order.groupBy('customerID','customerName','customerAddress').agg(countDistinct('orderID')).sort('customerID').show(truncate=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXa1Ve1TGai7",
        "outputId": "779ff7f0-b7fd-40eb-c97a-6c43b6af745c"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------------+--------------------+--------------+\n",
            "|customerID|customerName            |customerAddress     |count(orderID)|\n",
            "+----------+------------------------+--------------------+--------------+\n",
            "|1         |Contemporary Casuals    |1355 S Hines Blvd   |2             |\n",
            "|2         |Value Furniture         |15145 S.W. 17th St. |1             |\n",
            "|3         |Home Furnishings        |1900 Allard Ave.    |1             |\n",
            "|4         |Eastern Furniture       |1925 Beltline Rd.   |1             |\n",
            "|5         |Impressions             |5585 Westcott Ct.   |1             |\n",
            "|6         |Furniture Gallery       |325 Flatiron Dr.    |0             |\n",
            "|7         |Period Furniture        |394 Rainbow Dr.     |0             |\n",
            "|8         |California Classics     |816 Peach Rd.       |1             |\n",
            "|9         |M and H Casual Furniture|3709 First Street   |0             |\n",
            "|10        |Seminole Interiors      |2400 Rocky Point Dr.|0             |\n",
            "|11        |American Euro Lifestyles|2424 Missouri Ave N.|1             |\n",
            "|12        |Battle Creek Furniture  |345 Capitol Ave. SW |1             |\n",
            "|13        |Heritage Furnishings    |66789 College Ave.  |0             |\n",
            "|14        |Kaneohe Homes           |112 Kiowai St.      |0             |\n",
            "|15        |Mountain Scenes         |4132 Main Street    |1             |\n",
            "+----------+------------------------+--------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T61V-B90emMu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}